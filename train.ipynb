{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inpaint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [2, 3]\n",
    "# device_ids = [2]\n",
    "\n",
    "class config:\n",
    "    title = 'InpaintNet[test, 2 gpus, mean loss]'\n",
    "    \n",
    "    device = torch.device('cuda:{}'.format(device_ids[0])) if torch.cuda.is_available() else torch.device('cpu')\n",
    "    device_ids = device_ids  # used for multi-gpu\n",
    "    \n",
    "    train_dataset_path = '../celebA-HQ-all/train'\n",
    "    val_dataset_path = '../celebA-HQ-all/val'\n",
    "#     train_dataset_path = '../celebA-HQ-medium/train'\n",
    "#     val_dataset_path = '../celebA-HQ-medium/val'\n",
    "    masks_dir = '../quick_draw/'\n",
    "    \n",
    "    in_channels = 3\n",
    "    out_channels = 3\n",
    "    \n",
    "    train_batch_size = 8 * len(device_ids)\n",
    "    val_batch_size = 8 * len(device_ids)\n",
    "    \n",
    "    lr = 0.0001\n",
    "    \n",
    "    n_epochs = 1000000\n",
    "    \n",
    "    val_n_images_to_draw = 20\n",
    "    \n",
    "    checkpoints_root_path = './checkpoints'\n",
    "    tensorboard_path = './tensorboard'\n",
    "    \n",
    "    n_workers = 2\n",
    "    \n",
    "    # loss coefficients\n",
    "    valid_coef = 1\n",
    "    hole_coef = 6\n",
    "    perceptual_coef = 0.05\n",
    "    style_coef = 120\n",
    "    tv_coef = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = inpaint.make_dataloader(config.train_dataset_path, config.masks_dir,\n",
    "                                           batch_size=config.train_batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=config.n_workers)\n",
    "\n",
    "val_dataloader = inpaint.make_dataloader(config.val_dataset_path, config.masks_dir,\n",
    "                                         batch_size=config.val_batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=config.n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and associated stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inpaint.module.InpaintNet(config.in_channels, config.out_channels).to(config.device)\n",
    "\n",
    "if len(config.device_ids) > 1:\n",
    "    model = nn.DataParallel(model, device_ids=config.device_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaint_criterion = inpaint.module.InpaintLoss(\n",
    "    valid_coef=config.valid_coef,\n",
    "    hole_coef=config.hole_coef,\n",
    "    perceptual_coef=config.perceptual_coef,\n",
    "    style_coef=config.style_coef,\n",
    "    tv_coef=config.tv_coef,\n",
    ").to(config.device)\n",
    "\n",
    "if len(config.device_ids) > 1:\n",
    "    inpaint_criterion = nn.DataParallel(inpaint_criterion, device_ids=config.device_ids)\n",
    "\n",
    "l1_criterion = nn.L1Loss().to(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard writer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '{}@{}'.format(config.title, datetime.now().strftime(\"%d.%m.%Y-%H:%M:%S\"))\n",
    "print(experiment_name)\n",
    "\n",
    "writer = SummaryWriter(os.path.join(config.tensorboard_path, experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = os.path.join(config.checkpoints_root_path, experiment_name)\n",
    "if not os.path.exists(checkpoints_dir):\n",
    "    os.makedirs(checkpoints_dir)\n",
    "    \n",
    "print(checkpoints_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_mask(mask_batch, n_channels):\n",
    "    return torch.cat([mask_batch.unsqueeze(1)] * n_channels, dim=1)\n",
    "\n",
    "def preprocess_batch(batch):\n",
    "    image_batch, mask_batch = batch\n",
    "    image_batch, mask_batch = image_batch.type(torch.float32), mask_batch.type(torch.float32)\n",
    "    \n",
    "    mask_batch = expand_mask(mask_batch, config.in_channels)\n",
    "    \n",
    "    image_masked_batch = image_batch * mask_batch\n",
    "    \n",
    "    return image_batch, image_masked_batch, mask_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in tqdm(train_dataloader):\n",
    "    image_batch, image_masked_batch, mask_batch = preprocess_batch(batch)\n",
    "    \n",
    "    for image, image_masked, mask in zip(image_batch, image_masked_batch, mask_batch):\n",
    "        plt.imshow(image.numpy().transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(image_masked.numpy().transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(mask.numpy().transpose((1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "    i += 1\n",
    "    if i >= 1: break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "times = {\n",
    "    'train_inference': [],\n",
    "    'val_inference': [],\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'backprop': [],\n",
    "    'train_all': [],\n",
    "    'val_all': [],\n",
    "    'train_batch': [],\n",
    "    'epoch': []\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for epoch in range(config.n_epochs):\n",
    "    epoch_start = time()\n",
    "    \n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    \n",
    "    # dump model's parameters tensorboard\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, param.clone().to('cpu').data.numpy(), epoch)\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_inpaint_loss = train_l1_loss = train_batches = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        train_all_start = time()\n",
    "        \n",
    "        train_batch_start = time()\n",
    "        image_batch, image_masked_batch, mask_batch = preprocess_batch(batch)\n",
    "        times['train_batch'].append(time() - train_batch_start)\n",
    "        \n",
    "        # to device\n",
    "        image_batch = image_batch.to(config.device)\n",
    "        image_masked_batch = image_masked_batch.to(config.device)\n",
    "        mask_batch = mask_batch.to(config.device)\n",
    "        \n",
    "        # inference and backprop\n",
    "        train_inference_start = time()\n",
    "        image_pred_batch, _ = model(image_masked_batch, mask_batch)\n",
    "        times['train_inference'].append(time() - train_inference_start)\n",
    "        \n",
    "        train_loss_start = time()\n",
    "        inpaint_loss = inpaint_criterion(image_pred_batch, mask_batch, image_batch)\n",
    "        inpaint_loss = torch.mean(inpaint_loss)  # it returns multiple values (done for multi-gpu)\n",
    "        times['train_loss'].append(time() - train_loss_start)\n",
    "        \n",
    "        backprop_start = time()\n",
    "        inpaint_loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        times['backprop'].append(time() - backprop_start)\n",
    "                \n",
    "        # measure L1 loss\n",
    "        l1_loss = l1_criterion(image_pred_batch, image_batch)\n",
    "        \n",
    "        # collect metrics\n",
    "        n_iters = epoch * len(train_dataloader) + train_batches\n",
    "        writer.add_scalar('train/inpaint_loss', inpaint_loss.item(), n_iters)\n",
    "        writer.add_scalar('train/l1_loss', l1_loss.item(), n_iters)\n",
    "        \n",
    "        train_inpaint_loss += inpaint_loss.item()\n",
    "        train_l1_loss += l1_loss.item()\n",
    "        train_batches += 1\n",
    "        \n",
    "        times['train_all'].append(time() - train_all_start)\n",
    "        \n",
    "    print('Train inpaint_loss:\\t{:.5}, l1_loss:\\t{:.5}'.format(\n",
    "        train_inpaint_loss / train_batches, train_l1_loss / train_batches\n",
    "    ))\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_inpaint_loss = val_l1_loss = val_batches =  0\n",
    "    n_images_drawn = 0\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        image_batch, image_masked_batch, mask_batch = preprocess_batch(batch)\n",
    "        \n",
    "        # to device\n",
    "        with torch.no_grad():\n",
    "            image_batch = image_batch.to(config.device)\n",
    "            image_masked_batch = image_masked_batch.to(config.device)\n",
    "            mask_batch = mask_batch.to(config.device)\n",
    "        \n",
    "        # inference\n",
    "        image_pred_batch, _ = model(image_masked_batch, mask_batch)\n",
    "        inpaint_loss = inpaint_criterion(image_pred_batch, mask_batch, image_batch)\n",
    "        inpaint_loss = torch.mean(inpaint_loss)\n",
    "        \n",
    "        # measure L1 loss\n",
    "        l1_loss = l1_criterion(image_pred_batch, image_batch)\n",
    "        \n",
    "        # collect metrics\n",
    "        n_iters = epoch * len(val_dataloader) + val_batches\n",
    "        if n_images_drawn < config.val_n_images_to_draw:\n",
    "            writer.add_image('val/image_pred_{}'.format(n_images_drawn), torch.clamp(image_pred_batch[0], 0, 1), epoch)\n",
    "            writer.add_image('val/image_masked_{}'.format(n_images_drawn), torch.clamp(image_masked_batch[0], 0, 1), epoch)\n",
    "            writer.add_image('val/mask_{}'.format(n_images_drawn), torch.clamp(mask_batch[0], 0, 1), epoch)\n",
    "            \n",
    "        n_images_drawn += 1\n",
    "        \n",
    "        val_inpaint_loss += inpaint_loss.item()\n",
    "        val_l1_loss += l1_loss.item()\n",
    "        val_batches += 1\n",
    "        \n",
    "    writer.add_scalar('val/inpaint_loss', val_inpaint_loss / val_batches, epoch)\n",
    "    writer.add_scalar('val/l1_loss', val_l1_loss / val_batches, epoch)\n",
    "    \n",
    "    print('Val inpaint_loss:\\t{:.5}, l1_loss:\\t{:.5}'.format(\n",
    "        val_inpaint_loss / val_batches, val_l1_loss / val_batches\n",
    "    ))\n",
    "    print()\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(checkpoints_dir, '{}.pth'.format(epoch)))\n",
    "    \n",
    "    times['epoch'].append(time() - epoch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in times.items():\n",
    "    print(k, np.mean(v) if len(v) > 0 else None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
